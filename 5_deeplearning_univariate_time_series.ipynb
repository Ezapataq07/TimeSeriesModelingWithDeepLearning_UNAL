{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1b611f",
   "metadata": {},
   "source": [
    "# Estructuras de redes profundas para series de tiempo univariadas\n",
    "\n",
    "Para este ejercicio, utilizaremos datos históricos de precios de Ethereum (ETH) desde su lanzamiento en 2015 hasta 2025. descargue los datos aquí: [eth-usd-max.csv](eth-usd-max.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e25c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "import pandas as pd\n",
    "\n",
    "data= pd.read_csv(\"/Users/nataliaacevedo/SeriesTemporalesDeepLearning/notebooks/modelo DL/eth-usd-max.csv\", index_col=0)\n",
    "# Dar formato de fecha a el índice\n",
    "data.index= pd.to_datetime(data.index)\n",
    "price= data[\"price\"]\n",
    "price.info()\n",
    "price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3539b6a",
   "metadata": {},
   "source": [
    "```text\n",
    "<class 'pandas.core.series.Series'>\n",
    "DatetimeIndex: 3647 entries, 2015-08-07 00:00:00+00:00 to 2025-08-01 00:00:00+00:00\n",
    "Series name: price\n",
    "Non-Null Count  Dtype  \n",
    "--------------  -----  \n",
    "3647 non-null   float64\n",
    "dtypes: float64(1)\n",
    "memory usage: 57.0 KB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc2c0ea",
   "metadata": {},
   "source": [
    "```text\n",
    "snapped_at\n",
    "2015-08-07 00:00:00+00:00    2.831620\n",
    "2015-08-08 00:00:00+00:00    1.330750\n",
    "2015-08-10 00:00:00+00:00    0.687586\n",
    "2015-08-11 00:00:00+00:00    1.067379\n",
    "2015-08-12 00:00:00+00:00    1.256613\n",
    "Name: price, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33229958",
   "metadata": {},
   "source": [
    "## Análisis de la serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62ee24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendimiento logarítmico del ETH\n",
    "import numpy as np\n",
    "log_returns = np.log(price / price.shift(1)).dropna()\n",
    "log_returns.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a0e363",
   "metadata": {},
   "source": [
    "```text\n",
    "count    3646.000000\n",
    "mean        0.001968\n",
    "std         0.055915\n",
    "min        -0.755106\n",
    "25%        -0.020145\n",
    "50%         0.000756\n",
    "75%         0.024395\n",
    "max         0.439775\n",
    "Name: price, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a6226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(log_returns, title=\"Rendimientos Logarítmicos del ETH\", labels={\"index\": \"Fecha\", \"value\": \"Rendimientos Logarítmicos\"})\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Fecha\",\n",
    "    yaxis_title=\"Rendimientos Logarítmicos\",\n",
    "    xaxis=dict(tickformat=\"%Y\")  # Formato para mostrar solo los años\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db76332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_acf(log_returns, lags=50, title=\"ACF de los Rendimientos Logarítmicos del ETH\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc59e08",
   "metadata": {},
   "source": [
    "![](deeplearning_files/deeplearning_5_0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4df0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "plot_pacf(log_returns, lags=50, title=\"PACF de los Rendimientos Logarítmicos del ETH\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af160635",
   "metadata": {},
   "source": [
    "![](deeplearning_files/deeplearning_6_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee5fdef",
   "metadata": {},
   "source": [
    "No hay evidencia estadísticamente significativa de autocorrelación en\n",
    "los rendimientos del ETH.\n",
    "\n",
    "Los rendimientos parecen ser independientes en el tiempo (al menos\n",
    "linealmente), lo cual es típico de series financieras bien especificadas\n",
    "(retornos ≈ ruido blanco).\n",
    "\n",
    "Esto no implica que la varianza sea constante; puede existir\n",
    "heteroscedasticidad (volatilidad variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d424f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "#prueba de raices unitarias ADF\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "adf_result = adfuller(log_returns)\n",
    "print(\"ADF Statistic:\", adf_result[0])\n",
    "print(\"p-value:\", adf_result[1])\n",
    "\n",
    "\n",
    "# Prueba de Ljung-Box\n",
    "ljung_box_test = acorr_ljungbox(log_returns, lags=[10], return_df=True)\n",
    "print(ljung_box_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840162eb",
   "metadata": {},
   "source": [
    "```text\n",
    "ADF Statistic: -11.4460084631789\n",
    "p-value: 6.016416114763928e-21\n",
    "      lb_stat  lb_pvalue\n",
    "10  12.902362   0.229182\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c0dcd",
   "metadata": {},
   "source": [
    "La prueba ADF muestra evidencia muy fuerte de estacionariedad en los\n",
    "rendimientos del ETH. Es decir, no hay raíz unitaria, la serie no tiene\n",
    "tendencia sistemática, y sus fluctuaciones son estables alrededor de una\n",
    "media constante (ruido blanco con posible heteroscedasticidad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8842935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba ARCH para heteroscedasticidad\n",
    "from statsmodels.stats.diagnostic import het_arch\n",
    "arch_test = het_arch(log_returns)\n",
    "print(\"ARCH Test Statistic:\", arch_test[0])\n",
    "print(\"p-value:\", arch_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e84b6d",
   "metadata": {},
   "source": [
    "```text\n",
    "ARCH Test Statistic: 242.72418427640844\n",
    "p-value: 1.835123604303998e-46\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f1ed3",
   "metadata": {},
   "source": [
    "Las series financieras, energéticas, macroeconómicas, climáticas y de\n",
    "demanda son las que más frecuentemente presentan varianza no constante.\n",
    "\n",
    "Una serie no presenta varianza constante cuando la magnitud de sus\n",
    "fluctuaciones cambia con el tiempo, mostrando períodos de alta y baja\n",
    "volatilidad (lo que en finanzas llamamos volatility clustering).\n",
    "\n",
    "Gráficamente, la amplitud de los valores se “estrecha” o se “ensancha”\n",
    "en distintos tramos de la serie.\n",
    "\n",
    "Series típicamente no homocedásticas (varianza no constante)\n",
    "\n",
    "+---------------------+------------------------+-----------------------------+\n",
    "| Tipo de serie       | Ejemplo                | Por qué no tienen varianza  |\n",
    "|                     |                        | constante                   |\n",
    "+=====================+========================+=============================+\n",
    "| **Financieras       | Retornos de acciones,  | Exhiben **clustering de     |\n",
    "| (retornos, precios, | criptomonedas, tasas   | volatilidad**: periodos de  |\n",
    "| tasas)**            | de cambio, commodities | calma seguidos de           |\n",
    "|                     |                        | turbulencia                 |\n",
    "+---------------------+------------------------+-----------------------------+\n",
    "| **Energéticas**     | Precios del petróleo,  | Alta sensibilidad a choques |\n",
    "|                     | gas, electricidad      | externos y estacionalidad   |\n",
    "|                     |                        | en la volatilidad           |\n",
    "+---------------------+------------------------+-----------------------------+\n",
    "| **Macroeconómicas** | Inflación, PIB,        | Cambios estructurales,      |\n",
    "|                     | desempleo, tasas de    | shocks de política          |\n",
    "|                     | interés                | económica o crisis          |\n",
    "+---------------------+------------------------+-----------------------------+\n",
    "| **Meteorológicas /  | Temperatura,           | Fenómenos extremos o        |\n",
    "| Climáticas**        | precipitación,         | estacionales que modifican  |\n",
    "|                     | velocidad del viento   | la amplitud                 |\n",
    "+---------------------+------------------------+-----------------------------+\n",
    "| **Demanda / Consumo | Demanda eléctrica,     | Varianza mayor en horas     |\n",
    "| energético**        | tráfico de red,        | pico o temporadas altas     |\n",
    "|                     | transporte             |                             |\n",
    "+---------------------+------------------------+-----------------------------+\n",
    "| **Series biomédicas | Frecuencia cardíaca,   | Responden a estímulos o     |\n",
    "| / fisiológicas**    | señales EEG, presión   | eventos fisiológicos con    |\n",
    "|                     | arterial               | varianza variable           |\n",
    "+---------------------+------------------------+-----------------------------+\n",
    "| **Series económicas | Volumen de comercio,   | Aumentan su varianza con el |\n",
    "| agregadas**         | producción industrial  | tamaño o la escala del      |\n",
    "|                     |                        | sistema                     |\n",
    "+---------------------+------------------------+-----------------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14655131",
   "metadata": {},
   "source": [
    "## Ajustar un modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0456153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "train_size = int(len(log_returns) * 0.8)\n",
    "train, test = log_returns[:train_size], log_returns[train_size:]\n",
    "print(f\"Train size: {len(train)}, Test size: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e886a0",
   "metadata": {},
   "source": [
    "```text\n",
    "Train size: 2916, Test size: 730\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6327cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraer las secuencias para los rendimientos logarítmicos para train y test\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "        targets.append(data[i + seq_length])\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "seq_length = 20  # Número de días anteriores para predecir el siguiente día\n",
    "\n",
    "X_train, y_train = create_sequences(train.values, seq_length)\n",
    "X_test, y_test = create_sequences(test.values, seq_length)\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87762d13",
   "metadata": {},
   "source": [
    "```text\n",
    "Shape of X_train: (2896, 20)\n",
    "Shape of y_train: (2896,)\n",
    "Shape of X_test: (710, 20)\n",
    "Shape of y_test: (710,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Escalar las secuencias con MinMaxScaler para train y test\n",
    "\n",
    "scaler_X = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler_y = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# Solo se ajusta con el TRAIN\n",
    "X_train_scaled = scaler_X.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "\n",
    "# El TEST solo se transforma con los límites del TRAIN\n",
    "X_test_scaled = scaler_X.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(\"Scaled X_train shape:\", X_train_scaled.shape)\n",
    "print(\"Scaled y_train shape:\", y_train_scaled.shape)\n",
    "print(\"Scaled X_test shape:\", X_test_scaled.shape)\n",
    "print(\"Scaled y_test shape:\", y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb2d489",
   "metadata": {},
   "source": [
    "```text\n",
    "Scaled X_train shape: (2896, 20)\n",
    "Scaled y_train shape: (2896,)\n",
    "Scaled X_test shape: (710, 20)\n",
    "Scaled y_test shape: (710,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adfb0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "\n",
    "# Asegurarse de que X tenga tres dimensiones\n",
    "X = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "print(\"Reshaped X shape:\", X.shape)\n",
    "\n",
    "# Crear el modelo LSTM\n",
    "model = Sequential([\n",
    "    Input(shape=(X.shape[1], X.shape[2])),  # Define explícitamente la forma de entrada\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(32, activation='tanh'),\n",
    "    Dense(1)  # Capa de salida con una neurona para la predicción\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce68c33",
   "metadata": {},
   "source": [
    "```text\n",
    "Reshaped X shape: (2896, 20, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ea708",
   "metadata": {},
   "source": [
    "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4be344",
   "metadata": {},
   "source": [
    "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78be31f6",
   "metadata": {},
   "source": [
    "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,345</span> (114.63 KB)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc937b1",
   "metadata": {},
   "source": [
    "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,345</span> (114.63 KB)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cea463",
   "metadata": {},
   "source": [
    "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7fba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fijar el valor semilla \n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# entrenar el modelo\n",
    "history = model.fit(X_train_scaled, y_train_scaled, epochs=200, batch_size=32, validation_split=0.2, verbose=0)\n",
    "# graficar la pérdida de entrenamiento y validación con plotly\n",
    "import plotly.graph_objects as go   \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=history.history['loss'], mode='lines', name='Pérdida de Entrenamiento'))\n",
    "fig.add_trace(go.Scatter(y=history.history['val_loss'], mode='lines', name='Pérdida de Validación'))\n",
    "fig.update_layout(\n",
    "    title=\"Pérdida de Entrenamiento y Validación\",\n",
    "    xaxis_title=\"Épocas\",\n",
    "    yaxis_title=\"Pérdida (MSE)\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0920d0",
   "metadata": {},
   "source": [
    "![](deeplearning_files/deeplearning_7_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2a34a1",
   "metadata": {},
   "source": [
    "+----------------+------------------------------------------------------+\n",
    "| Evidencia      | Interpretación                                       |\n",
    "+================+======================================================+\n",
    "| ``train_loss`` | El modelo sigue ajustando cada vez mejor los datos   |\n",
    "| ↓ constante    | de entrenamiento.                                    |\n",
    "+----------------+------------------------------------------------------+\n",
    "| ``val_loss`` ↓ | El modelo comienza a memorizar detalles del conjunto |\n",
    "| al inicio y    | de entrenamiento y pierde capacidad de               |\n",
    "| luego ↑        | generalización.                                      |\n",
    "+----------------+------------------------------------------------------+\n",
    "| Punto de       | A partir de allí, el modelo deja de generalizar;     |\n",
    "| inflexión      | debería haberse detenido antes.                      |\n",
    "| (~época 150)   |                                                      |\n",
    "+----------------+------------------------------------------------------+\n",
    "\n",
    "EL modelo aprende correctamente (no hay underfitting ni gradientes\n",
    "muertos).\n",
    "\n",
    "La arquitectura tiene suficiente capacidad.\n",
    "\n",
    "El modelo necesita un mecanismo de regularización o parada temprana para\n",
    "evitar memorizar el ruido final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predecir con el modelo entrenado\n",
    "y_pred_scaled = model.predict(X_train_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# graficar las predicciones vs los valores reales\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=y_train, mode='lines', name='Valores Reales'))\n",
    "fig.add_trace(go.Scatter(y=y_pred, mode='lines', name='Predicciones del Modelo'))\n",
    "fig.update_layout(\n",
    "    title=\"Predicciones vs Valores Reales\",\n",
    "    xaxis_title=\"Días\",\n",
    "    yaxis_title=\"Rendimientos Logarítmicos\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f406ea",
   "metadata": {},
   "source": [
    "![](deeplearning_files/deeplearning_8_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedaac47",
   "metadata": {},
   "source": [
    "```text\n",
    "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b0f69c",
   "metadata": {},
   "source": [
    "Esto es el patrón clásico de sobreajuste leve (overfitting):\n",
    "\n",
    "Evidencia Interpretación train_loss ↓ constante El modelo sigue\n",
    "ajustando cada vez mejor los datos de entrenamiento. val_loss ↓ al\n",
    "inicio y luego ↑ El modelo comienza a memorizar detalles del conjunto de\n",
    "entrenamiento y pierde capacidad de generalización. Punto de inflexión\n",
    "(~época 150) A partir de allí, el modelo deja de generalizar; debería\n",
    "haberse detenido antes.\n",
    "\n",
    "¿Por qué regularizar una LSTM?\n",
    "\n",
    "Las LSTM tienen muchos parámetros (por las 4 puertas internas), por lo\n",
    "que pueden:\n",
    "\n",
    "- Memorizar ruido.\n",
    "- Aprender relaciones espurias.\n",
    "- O no generalizar a datos futuros (especialmente en backtesting\n",
    "  temporal).\n",
    "\n",
    "Regularizar ayuda a: \\* Controlar la complejidad. \\* Reducir la\n",
    "varianza. \\* Y mejorar la capacidad de generalización a nuevos periodos.\n",
    "\n",
    "+-----------------------+---------------------------+-------------+-------------------+\n",
    "| Tipo                  | Cuándo                    | Valor       | Observación       |\n",
    "|                       |                           | típico      |                   |\n",
    "+=======================+===========================+=============+===================+\n",
    "| ``L2``                | Siempre útil, sobre todo  | 1e-4 – 1e-3 | Penaliza pesos    |\n",
    "|                       | con pocos datos           |             | grandes           |\n",
    "+-----------------------+---------------------------+-------------+-------------------+\n",
    "| ``dropout``           | Contra sobreajuste en     | 0.2–0.4     | Muy efectivo      |\n",
    "|                       | entradas                  |             |                   |\n",
    "+-----------------------+---------------------------+-------------+-------------------+\n",
    "| ``recurrent_dropout`` | Contra dependencias       | 0.1–0.2     | Cuidado con       |\n",
    "|                       | falsas                    |             | secuencias cortas |\n",
    "+-----------------------+---------------------------+-------------+-------------------+\n",
    "| ``EarlyStopping``     | Siempre                   | patience=10 | Mejora            |\n",
    "|                       |                           | o 20        | generalización    |\n",
    "+-----------------------+---------------------------+-------------+-------------------+\n",
    "| ``clipnorm``          | En secuencias largas      | 1–5         | Evita             |\n",
    "|                       |                           |             | inestabilidad     |\n",
    "+-----------------------+---------------------------+-------------+-------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51852ebb",
   "metadata": {},
   "source": [
    "## Ajustar un LSTM con Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "# Crear el modelo LSTM\n",
    "model_reg = Sequential([\n",
    "    Input(shape=(X.shape[1], X.shape[2])),  # Define explícitamente la forma de entrada\n",
    "    LSTM(64, activation='tanh', return_sequences=True),\n",
    "    LSTM(32, activation='tanh', return_sequences=False),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-3)\n",
    "# Compilar el modelo\n",
    "model_reg.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3410c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "#fijar el valor semilla \n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# entrenar el modelo\n",
    "history_reg = model_reg.fit(X_train_scaled, y_train_scaled, epochs=200, batch_size=32, validation_split=0.2, verbose=0, callbacks=[early_stopping])\n",
    "# graficar la pérdida de entrenamiento y validación con plotly\n",
    "import plotly.graph_objects as go   \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=history_reg.history['loss'], mode='lines', name='Pérdida de Entrenamiento'))\n",
    "fig.add_trace(go.Scatter(y=history_reg.history['val_loss'], mode='lines', name='Pérdida de Validación'))\n",
    "fig.update_layout(\n",
    "    title=\"Pérdida de Entrenamiento y Validación\",\n",
    "    xaxis_title=\"Épocas\",\n",
    "    yaxis_title=\"Pérdida (MSE)\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ec0d0c",
   "metadata": {},
   "source": [
    "![](deeplearning_files/deeplearning_9_0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones con el conjunto de test\n",
    "y_test_pred_scaled = model.predict(X_test_scaled)\n",
    "y_test_pred_m1 = scaler_y.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Graficar las predicciones vs los valores reales del conjunto de test\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=y_test, mode='lines', name='Valores Reales (Test)'))\n",
    "fig.add_trace(go.Scatter(y=y_test_pred_m1, mode='lines', name='Predicciones del Modelo (Test)'))\n",
    "fig.update_layout(\n",
    "    title=\"Predicciones M1 vs Valores Reales (Conjunto de Test)\",\n",
    "    xaxis_title=\"Días\",\n",
    "    yaxis_title=\"Rendimientos Logarítmicos\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dac539d",
   "metadata": {},
   "source": [
    "![](deeplearning_files/deeplearning_10_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206dfae8",
   "metadata": {},
   "source": [
    "```text\n",
    "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca800cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobar métricas en conjunto de test\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(y_test_pred_m1, y_test)\n",
    "mae = mean_absolute_error(y_test_pred_m1, y_test)\n",
    "print(\"Mean Squared Error (MSE)-M1:\", mse)\n",
    "print(\"Mean Absolute Error (MAE)-M1:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f34ccfa",
   "metadata": {},
   "source": [
    "```text\n",
    "Mean Squared Error (MSE)-M1: 0.0012814059785279802\n",
    "Mean Absolute Error (MAE)-M1: 0.025549416435279443\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457baac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones con el conjunto de test con modelo Regularizado\n",
    "y_test_pred_scaled = model_reg.predict(X_test_scaled)\n",
    "y_test_pred_m2 = scaler_y.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Graficar las predicciones vs los valores reales del conjunto de test\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=y_test, mode='lines', name='Valores Reales (Test)'))\n",
    "fig.add_trace(go.Scatter(y=y_test_pred_m2, mode='lines', name='Predicciones del Modelo (Test)'))\n",
    "fig.update_layout(\n",
    "    title=\"Predicciones M2 vs Valores Reales (Conjunto de Test)\",\n",
    "    xaxis_title=\"Días\",\n",
    "    yaxis_title=\"Rendimientos Logarítmicos\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08ed6c",
   "metadata": {},
   "source": [
    "![](deeplearning_files/deeplearning_11_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec759ef2",
   "metadata": {},
   "source": [
    "```text\n",
    "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c73c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobar métricas en conjunto de test\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "mse = mean_squared_error(y_test_pred_m2, y_test)\n",
    "mae = mean_absolute_error(y_test_pred_m2, y_test)\n",
    "print(\"Mean Squared Error (MSE)-M2:\", mse)\n",
    "print(\"Mean Absolute Error (MAE)-M2:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d9fa2",
   "metadata": {},
   "source": [
    "```text\n",
    "Mean Squared Error (MSE)-M2: 0.0011946981891149161\n",
    "Mean Absolute Error (MAE)-M2: 0.024036314007303047\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909616c1",
   "metadata": {},
   "source": [
    "## Comparar con un modelo clásico GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model\n",
    "\n",
    "# Ajustar un modelo GARCH(1,1) a los rendimientos logarítmicos\n",
    "garch_model = arch_model(log_returns, vol='Garch', p=1, q=1, mean='Constant', dist='normal', rescale=False)\n",
    "garch_fit = garch_model.fit(disp='off')\n",
    "\n",
    "# Resumen del modelo ajustado\n",
    "print(garch_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b768ce6",
   "metadata": {},
   "source": [
    "```text\n",
    "                     Constant Mean - GARCH Model Results                      \n",
    "==============================================================================\n",
    "Dep. Variable:                  price   R-squared:                       0.000\n",
    "Mean Model:             Constant Mean   Adj. R-squared:                  0.000\n",
    "Vol Model:                      GARCH   Log-Likelihood:                5960.65\n",
    "Distribution:                  Normal   AIC:                          -11913.3\n",
    "Method:            Maximum Likelihood   BIC:                          -11888.5\n",
    "                                        No. Observations:                 3646\n",
    "Date:                Tue, Oct 28 2025   Df Residuals:                     3645\n",
    "Time:                        19:46:20   Df Model:                            1\n",
    "                                 Mean Model                                 \n",
    "============================================================================\n",
    "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
    "----------------------------------------------------------------------------\n",
    "mu         1.6880e-03  7.010e-04      2.408  1.605e-02 [3.140e-04,3.062e-03]\n",
    "                              Volatility Model                              \n",
    "============================================================================\n",
    "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
    "----------------------------------------------------------------------------\n",
    "omega      1.2037e-04  4.616e-05      2.607  9.122e-03 [2.989e-05,2.108e-04]\n",
    "alpha[1]       0.1298  3.165e-02      4.101  4.113e-05   [6.776e-02,  0.192]\n",
    "beta[1]        0.8305  4.177e-02     19.883  5.718e-88     [  0.749,  0.912]\n",
    "============================================================================\n",
    "\n",
    "Covariance estimator: robust\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bc0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtener las predicciones del modelo GARCH\n",
    "garch_predictions = garch_fit.conditional_volatility\n",
    "\n",
    "# Graficar los valores reales y las predicciones\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(log_returns.index, log_returns, label='Valores Reales', color='blue', alpha=0.6)\n",
    "plt.plot(log_returns.index, garch_predictions, label='Predicciones GARCH (Volatilidad Condicional)', color='red', alpha=0.8)\n",
    "plt.title('Comparación de Rendimientos Reales y Predicciones del Modelo GARCH')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Rendimientos Logarítmicos')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b1fa3f",
   "metadata": {},
   "source": [
    "![](deeplearning_files/deeplearning_32_0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f938e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predicciones del conjunto de entrenamiento\n",
    "garch_train_predictions = garch_fit.conditional_volatility\n",
    "\n",
    "# Predicciones del conjunto de prueba\n",
    "garch_forecast = garch_fit.forecast(horizon=len(y_test), reindex=False)\n",
    "garch_test_predictions = np.sqrt(garch_forecast.variance.values[-1])  # Raíz cuadrada para obtener la desviación estándar\n",
    "\n",
    "# Graficar los valores reales y las predicciones\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Ensure the lengths of train.index and garch_train_predictions match\n",
    "garch_train_predictions = garch_train_predictions[:len(train)]\n",
    "\n",
    "# Ensure the lengths of test.index and garch_test_predictions match\n",
    "garch_test_predictions = garch_test_predictions[:len(y_test)]  # Align with y_test length\n",
    "\n",
    "plt.plot(train.index[:len(garch_train_predictions)], train[:len(garch_train_predictions)], label='Valores Reales (Entrenamiento)', color='blue', alpha=0.6)\n",
    "plt.plot(train.index[:len(garch_train_predictions)], garch_train_predictions, label='Predicciones GARCH (Entrenamiento)', color='red', alpha=0.8)\n",
    "plt.plot(test.index[:len(garch_test_predictions)], test[:len(garch_test_predictions)], label='Valores Reales (Test)', color='green', alpha=0.6)\n",
    "plt.plot(test.index[:len(garch_test_predictions)], garch_test_predictions, label='Predicciones GARCH (Test)', color='orange', alpha=0.8)\n",
    "plt.title('Comparación de Predicciones del Modelo GARCH: Entrenamiento vs Test')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Rendimientos Logarítmicos')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf812a9a",
   "metadata": {},
   "source": [
    "![](deeplearning_files/deeplearning_33_0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8273948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el MSE y MAE para el modelo GARCH en el conjunto de test\n",
    "mse_garch = mean_squared_error(y_test, garch_test_predictions)\n",
    "mae_garch = mean_absolute_error(y_test, garch_test_predictions)\n",
    "\n",
    "print(\"Mean Squared Error (MSE) - GARCH:\", mse_garch)\n",
    "print(\"Mean Absolute Error (MAE) - GARCH:\", mae_garch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9244af",
   "metadata": {},
   "source": [
    "```text\n",
    "Mean Squared Error (MSE) - GARCH: 0.004017594643607091\n",
    "Mean Absolute Error (MAE) - GARCH: 0.05636287978694763\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b1e9c",
   "metadata": {},
   "source": [
    "## Resultados comparativos en el conjunto de Test\n",
    "\n",
    "+-----------+-----------+---------+-------------------------------------------------------+\n",
    "| Modelo    | MSE ↓     | MAE ↓   | Interpretación                                        |\n",
    "+===========+===========+=========+=======================================================+\n",
    "| **GARCH** | 0.0040176 | 0.05636 | Mayor error cuadrático y absoluto. Menor capacidad de |\n",
    "|           |           |         | ajuste a la dinámica reciente.                        |\n",
    "+-----------+-----------+---------+-------------------------------------------------------+\n",
    "| **M1**    | 0.0012814 | 0.02555 | Mejora notable respecto a GARCH. Captura mejor la     |\n",
    "|           |           |         | magnitud de los rendimientos.                         |\n",
    "+-----------+-----------+---------+-------------------------------------------------------+\n",
    "| **M2**    | 0.0011947 | 0.02404 | Mejor desempeño global. Menor error promedio y menor  |\n",
    "|           |           |         | desviación en predicciones extremas.                  |\n",
    "+-----------+-----------+---------+-------------------------------------------------------+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
